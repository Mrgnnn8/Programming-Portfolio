For this model I tried 2 Conv2D layers, 3 Conv2D layers and 4 Conv2D layers. Each layer was followed by a MaxPooling layer to reduce the size of the input. For the 2 layer version of the model I found the accuracy to not be that impressive so added another layer and found the model to be 97% accurate which I was happy with. When adding a fourth layer I found there to be a few isssues I had to debug. By MaxPooling each Conv2D layer I got too the point where if I did this after the 4th layer the image would be too small and so was reporting the error “ValueError: Negative dimension size caused by subtracting 3 from 2 …”. I tried using a fourth layer without a following MaxPool layer however the accuracy dropped to 95% from 97% so there I determined it wasn't necessary. 

I decided the fourth layer detracted from performance due to it pushing the model into “too big / too small” territory. Too many parameters to generalise, and too little spatial structure to learn from.

Along with this I experimented with dropout values 0.3, 0.5 and 0.7. I found that 0.5 was the most effective. This was expected and I belived it to be that 0.5 gives the right balance between strong regularisation and ability to form complex feature hierarchies. 